{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b02343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4eec2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADS\\AppData\\Local\\Temp\\ipykernel_18404\\3391605287.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n"
     ]
    }
   ],
   "source": [
    "# Launch the Chrome driver\n",
    "driver = webdriver.Chrome('C:\\chromedriver\\chromedriver')\n",
    "\n",
    "# Login to LinkedIn\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "username.send_keys(\"your_email_address\") # Enter your email address\n",
    "pword = driver.find_element(By.ID,\"password\")\n",
    "pword.send_keys(\"your_password\") # Enter your password\n",
    "# Click on the submit button to login\n",
    "driver.find_element(By.XPATH,\"//button[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeabb860",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.linkedin.com/school/institut-national-de-statistique-et-d-economie-appliquee-insea/people/\")\n",
    "#choose year between 1999 and 2018\n",
    "year = driver.find_element(By.ID,\"people-search-year-end\")\n",
    "year.send_keys(\"2018\") \n",
    "driver.find_element(By.XPATH,\"//input[@class='org-people__input-year fl']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4481ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll the page to load more profiles\n",
    "rep = 50 #determine the rep enough to scroll all the page\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "for i in range(rep):\n",
    "  driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "  time.sleep(5)\n",
    "  new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "  if new_height == last_height:\n",
    "    break\n",
    "  new_height = last_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f3b963d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract HTML source code of the page and parse it using BeautifulSoup\n",
    "src = driver.page_source \n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "# Find the target div element containing all the profiles\n",
    "pav = soup.find('div', {'class' : 'org-grid__content-height-enforcer'})\n",
    "all_links = pav.find_all('a', {'class' : 'app-aware-link link-without-visited-state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70dcd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract profile links for all the profiles on the page\n",
    "profilesID = []\n",
    "for link in all_links:\n",
    "  profilesID.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95938154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the extracted data\n",
    "names = []\n",
    "companies = []\n",
    "locs = []\n",
    "works= []\n",
    "\n",
    "# Iterate over all profile links and extract the desired data\n",
    "for profileID in profilesID[1:20]: # consider only 20 profiles for this example\n",
    "    fulllink = profileID\n",
    "    driver.get(fulllink)\n",
    "    time.sleep(8)\n",
    "    src = driver.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    \n",
    "    # Extract name\n",
    "    intro = soup.find('div', {'class': 'mt2 relative'})\n",
    "    name_loc = intro.find(\"h1\")\n",
    "    name = name_loc.get_text().strip()\n",
    "    names.append(name) \n",
    "    \n",
    "    # Extract location\n",
    "    location_loc = intro.find(\"span\", {'class': 'text-body-small inline t-black--light break-words'})\n",
    "    location = location_loc.get_text().strip()\n",
    "    locs.append(location)\n",
    "    \n",
    "    # Extract company\n",
    "    job = intro.find_all(\"span\", {'class': 'text-body-small'})\n",
    "    company = job[1].get_text().strip()\n",
    "    companies.append(company)\n",
    "\n",
    "    # Extract current job title\n",
    "    works_at_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
    "    works_at = works_at_loc.get_text().strip()\n",
    "    works.append(works_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5367c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(names, companies, locs, works)), \n",
    "               columns =['names', 'companies', 'locations', 'works']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70545cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('names', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef6910b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('INSEA_Alumni.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
